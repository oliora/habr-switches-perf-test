{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// Disable adding scrolling for outputs\n",
    "require(\n",
    "        [\"notebook/js/outputarea\"],\n",
    "        function (oa) {\n",
    "            oa.OutputArea.auto_scroll_threshold = -1;\n",
    "        });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "mpl.rcParams['figure.dpi'] = 75\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['axes.formatter.useoffset'] = False\n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filename: str):\n",
    "    algo_prefix_len_to_remove = len('algo')\n",
    "    def normalize(d):\n",
    "        d['input'] = d['input_file'].rsplit('/', 1)[1]\n",
    "        return d\n",
    "    with open(filename) as f:\n",
    "        return [normalize(json.loads(l)) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_algos = {\n",
    "    'naive': 1,\n",
    "    'naiveLessBranches': 1,\n",
    "    'naiveTableChar': 1,\n",
    "    'naiveTableInt': 1,\n",
    "\n",
    "    'autoVec_32': 2,\n",
    "    'autoVec_64': 2,\n",
    "    'autoVec_128_WithOverflow': 3,\n",
    "    'autoVec_128': 2,\n",
    "    'autoVec_128_IntStepCounter': 2,\n",
    "    'autoVec_256': 2,\n",
    "    'autoVec_256_IntStepCounter': 2,\n",
    "    'autoVec_512': 2,\n",
    "    'autoVec_1024': 2,\n",
    "    'autoVec_2048': 2,\n",
    "\n",
    "    'manualVec_32': 4,\n",
    "    'manualVec_64': 4,\n",
    "    'manualVec_128': 4,\n",
    "    'manualVec_256': 4,\n",
    "    'manualVec_512': 4,\n",
    "    'manualVec_1024': 4,\n",
    "    'manualVec_2048': 4,\n",
    "\n",
    "    'manualVecSize_32': 5,\n",
    "    'manualVecSize_64': 5,\n",
    "    'manualVecSize_128': 5,\n",
    "    'manualVecSize_256': 5,\n",
    "    'manualVecSize_512': 5,\n",
    "    'manualVecSize_1024': 5,\n",
    "    'manualVecSize_2048': 5,\n",
    "\n",
    "    'manualVecStrlen_32': 6,\n",
    "    'manualVecStrlen_64': 6,\n",
    "    'manualVecStrlen_128': 6,\n",
    "    'manualVecStrlen_256': 6,\n",
    "    'manualVecStrlen_512': 6,\n",
    "    'manualVecStrlen_1024': 6,\n",
    "    'manualVecStrlen_2048': 6,\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    1: 'bisque',\n",
    "    2: 'dodgerblue',\n",
    "    3: 'lightgrey',\n",
    "    4: 'lightpink',\n",
    "    4: 'lightpink',\n",
    "    5: 'olive',\n",
    "    6: 'paleturquoise',\n",
    "}\n",
    "\n",
    "HATCHES = {\n",
    "    1: '',\n",
    "    2: '',\n",
    "    3: 'x',\n",
    "    4: '..',\n",
    "    4: '..',\n",
    "    5: 'x',\n",
    "    6: '',\n",
    "}\n",
    "\n",
    "def make_sorter():\n",
    "    sort_order = {k: v for v, k in enumerate(all_algos.keys())}\n",
    "    return lambda s: s.map(lambda x: sort_order[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'amd-epyc': 'run-amd.log', # AMD EPYC 7282 physical server\n",
    "    'intel-icelake-aws': 'run-icelake-aws.txt', # Intel Xeon Platinum 8375C - m6i.metal AWS instance\n",
    "}\n",
    "\n",
    "data = {n: pd.DataFrame(load_results(fn)) for n, fn in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsd(x):\n",
    "    return x.std() / x.mean() * 100\n",
    "\n",
    "for arch, df in data.items():\n",
    "    print(arch)\n",
    "    print(df.groupby(['algo', 'input'])['mib_per_s'].agg(['max', 'min', 'mean', rsd]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of processing speed for null-terminated input\n",
    "\n",
    "Variants:\n",
    "- **algoHabrNaive** - original, the most naive algorithm from Habr\n",
    "- **algoHabrLessBranches** - algorithm from Habr that uses conditional move instead of branching\n",
    "- **algoHabrTableChar** - algorithm from Habr that uses a table with `signed char` values (-1, 0, 1) \n",
    "- **algoHabrTableInt** - algorithm from Habr that uses a table with `int` values (-1, 0, 1)\n",
    "- **algoHabrVectorized** - compiler-generated SIMD-based optimization from Habr that uses `signed char` for step sizes < 128 and `short` otherwise\n",
    "- **algoHabrVectorized_128_WithOverflow** - original version of **algoHabrVectorized** that uses `signed char` step counter with step sizes 128 hence suffer from a step counter overflow\n",
    "- **algoHabrVectorized_XXX_IntStepResult** - version of **algoHabrVectorized** that uses `int` for step counter\n",
    "- **autoVec** - manually written SIMD-based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos1 = [\n",
    "    'naive',\n",
    "    'naiveLessBranches',\n",
    "    'naiveTableChar',\n",
    "    'naiveTableInt',\n",
    "    'autoVec_32',\n",
    "    'autoVec_64',\n",
    "    'autoVec_128_WithOverflow',\n",
    "    'autoVec_128',\n",
    "    'autoVec_128_IntStepCounter',\n",
    "    'autoVec_256',\n",
    "    'autoVec_256_IntStepCounter',\n",
    "    'autoVec_512',\n",
    "    'autoVec_1024',\n",
    "    'autoVec_2048',\n",
    "    'manualVec_32',\n",
    "    'manualVec_64',\n",
    "    'manualVec_128',\n",
    "    'manualVec_256',\n",
    "    'manualVec_512',\n",
    "    'manualVec_1024',\n",
    "    'manualVec_2048',\n",
    "]\n",
    "\n",
    "hatches = [HATCHES[all_algos[a]] for a in algos1]\n",
    "colors = [COLORS[all_algos[a]] for a in algos1]\n",
    "\n",
    "for arch, df in data.items():\n",
    "    inputs = df['input'].unique()\n",
    "    for i, inp in enumerate(inputs):\n",
    "        df1 = df[df['algo'].isin(algos1) & (df['input'] == inp)]\n",
    "        g = df1.groupby(['algo']).max('mib_per_s').reset_index().sort_values('algo', key=make_sorter(), ignore_index=True)\n",
    "        plot, ax = plt.subplots(figsize=(24, 14), facecolor='whitesmoke', layout='tight')\n",
    "        inp_size = g[\"input_size\"][0] / 1024 / 1024\n",
    "        fig = g.plot.bar(x='algo', y='mib_per_s', ax=ax, title=f'Algorithm processing speed (the higher the better), arch={arch}, input={inp}, size={inp_size:.1f} MiB, best of all runs', legend=False, hatch=hatches, color=colors)\n",
    "        ax.set(xlabel=None, ylabel='MiB/s')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        ax.grid(which='both', axis='y')\n",
    "        ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of processing speed between algorithms which take null-terminated and known size input\n",
    "\n",
    "Variants:\n",
    "- **autoVec** - takes null-terminated string as input\n",
    "- **autoVecSize** - takes input buffer and size\n",
    "- **autoVecStrlen** - `strlen` + **autoVecSize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos2 = [\n",
    "    'manualVec_32',\n",
    "    'manualVec_64',\n",
    "    'manualVec_128',\n",
    "    'manualVec_256',\n",
    "    'manualVec_512',\n",
    "    'manualVec_1024',\n",
    "    'manualVec_2048',\n",
    "\n",
    "    'manualVecSize_32',\n",
    "    'manualVecSize_64',\n",
    "    'manualVecSize_128',\n",
    "    'manualVecSize_256',\n",
    "    'manualVecSize_512',\n",
    "    'manualVecSize_1024',\n",
    "    'manualVecSize_2048',\n",
    "\n",
    "    'manualVecStrlen_32',\n",
    "    'manualVecStrlen_64',\n",
    "    'manualVecStrlen_128',\n",
    "    'manualVecStrlen_256',\n",
    "    'manualVecStrlen_512',\n",
    "    'manualVecStrlen_1024',\n",
    "    'manualVecStrlen_2048',\n",
    "]\n",
    "\n",
    "hatches = [HATCHES[all_algos[a]] for a in algos2]\n",
    "colors = [COLORS[all_algos[a]] for a in algos2]\n",
    "\n",
    "for arch, df in data.items():\n",
    "    for i, inp in enumerate(inputs):\n",
    "        df1 = df[df['algo'].isin(algos2) & (df['input'] == inp)]\n",
    "        g = df1.groupby(['algo']).max('mib_per_s').reset_index().sort_values('algo', key=make_sorter(), ignore_index=True)\n",
    "        plot, ax = plt.subplots(figsize=(24, 14), facecolor='whitesmoke', layout='tight')\n",
    "        inp_size = g[\"input_size\"][0] / 1024 / 1024\n",
    "        fig = g.plot.bar(x='algo', y='mib_per_s', ax=ax, title=f'Processing speed (the higher the better), arch={arch}, input={inp}, size={inp_size:.1f} MiB, best of all runs', legend=False, hatch=hatches, color=colors)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        ax.set(xlabel=None, ylabel='MiB/s')\n",
    "        ax.grid(which='both', axis='y')\n",
    "        ax.bar_label(ax.containers[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
